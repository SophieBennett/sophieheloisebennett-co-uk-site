<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Sophie Bennett</title>
    <link>/</link>
    <description>Recent content on Sophie Bennett</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Tue, 20 Apr 2021 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Common Data Cleaning Mistakes... and How to Prevent Them</title>
      <link>/posts/common-data-cleaning-mistakes/</link>
      <pubDate>Tue, 20 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>/posts/common-data-cleaning-mistakes/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}div.highlightsql pre { color:#000;background-color:#ECECEC;}Recently, I’ve been thinking a lot about mistakes. Mistakes in how we store, handle and clean data can be extremely costly, but these mistakes are also incredibly easy to make. What’s more, data mistakes are often be semi-invisible; they don’t result in a website failing to load, or code not running. Instead, we obtain some data, an analysis or model is produced - it’s just the wrong data, an inaccurate model, or the wrong conclusion.</description>
    </item>
    
    <item>
      <title>Scraping Government Search Registers (with BeautifulSoup)</title>
      <link>/posts/school-web-scraping/</link>
      <pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/school-web-scraping/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}div.highlightsql pre { color:#000;background-color:#ECECEC;}Sadly no wacky data analysis projects to report this month (it’s been busy), so instead I’m going to go through a little web scraping project I did recently for my workplace. (In Python this time, largely for the purposes of my own learning and development).
The mission: From this search register, generate a list of schools plus the schools’ website domain name.</description>
    </item>
    
    <item>
      <title>On A Levels, Ofqual and Algorithms</title>
      <link>/posts/a-levels-2020/</link>
      <pubDate>Thu, 20 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/a-levels-2020/</guid>
      <description>A Level results day is always a hugely important day for students and teachers across the country; a day that can have profound impact on a student’s future. This year’s A Level results day, however, was a particularly noisy affair. Due to COVID-19, exams were cancelled and students’ grades were instead set by a controversial algorithm designed by Ofqual.
Since grades were released last week, there has been a huge amount of complaint about the process and outcomes, including amongst other things, criticism of the algorithm for promoting unfairness and increasing social inequality.</description>
    </item>
    
    <item>
      <title>Using Lag To Calculate Time Between Events in R and SQL</title>
      <link>/posts/calculating-response-times-with-lag/</link>
      <pubDate>Wed, 29 Jul 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/calculating-response-times-with-lag/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}div.highlightsql pre { color:#000;background-color:#ECECEC;}Last week, amidst building some dashboards for the customer experience team at work, I came across an interesting problem, which led me to a cool function called lag() that I hadn’t come across before. It struck me as a pretty common problem type for time-series data, so I thought I’d make a short blog post about it both for my own sake, and in case it can help anyone else out.</description>
    </item>
    
    <item>
      <title>When Is Simple Randomisation Enough?</title>
      <link>/posts/simple-randomisation-imbalance/</link>
      <pubDate>Sun, 14 Jun 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/simple-randomisation-imbalance/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}Random allocation of participants to experimental groups is a gold-standard for experimentation. We use random allocation to help ensure that participant characteristics are distributed evently across the experimental groups. This helps to avoid systematic differences between experimental groups at the start of the experiment.
But how should we randomly allocate our participants?
The most straightforward implementation is simple randomisation, where each participant is randomly assigned in turn to one of the experimental groups.</description>
    </item>
    
    <item>
      <title>Why Linear Regression Estimates the Conditional Mean</title>
      <link>/posts/linear-regression-conditional-mean/</link>
      <pubDate>Wed, 27 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/linear-regression-conditional-mean/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}Because you can never know too much about linear regression.
IntroductionIf you look at any textbook on linear regression, you will find that it says the following:
“Linear regression estimates the conditional mean of the response variable.”
This means that, for a given value of the predictor variable \(X\), linear regression will give you the mean value of the response variable \(Y\).</description>
    </item>
    
    <item>
      <title>Animal Crossing New Horizons: A New Birthday Problem</title>
      <link>/posts/birthdays-animal-crossing/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/birthdays-animal-crossing/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}In a room of 23 people, what’s the probability that at least two of them will share the same birthday? The answer is around 50%, a lot more than people usually expect.
This is an example of the classic Birthday Problem. The trick to calculating it is to start by calculating the complement, - i.e. the probability that no one in the room shares the same birthday.</description>
    </item>
    
    <item>
      <title>Gains Checker - An Adventure in Shiny Apps</title>
      <link>/posts/gains-checker-shiny-apps/</link>
      <pubDate>Sat, 25 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/gains-checker-shiny-apps/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}I’ve been working on my physical strength on and off for around 2.5 years now. I love strength training. It’s great for a number of reasons; t helps you maintain your muscles as you get older and build stronger bones, it can help improve your posture and give you a more toned body, and you get a sense of relatively rapid progression.</description>
    </item>
    
    <item>
      <title>Is Your Box of Celebrations Chocolates Biased?</title>
      <link>/posts/binomials-with-celebrations/</link>
      <pubDate>Thu, 16 Apr 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/binomials-with-celebrations/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}We surely all know the feeling of disappointment when the best chocolates in the Celebrations box are all gone and there’s only the rubbish ones left in the tub. Myself being particularly fond of the Malteasers and Galaxy chocolates, I’ve often felt a little suspicious that there might not be as many of them in a box than the other chocolates. But, I’ve never had a chance to put my suspicions to the test…</description>
    </item>
    
    <item>
      <title>Predicting School GCSE grades</title>
      <link>/posts/predicting-gcses/</link>
      <pubDate>Tue, 31 Mar 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/predicting-gcses/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}Every year, the UK government releases a comprehensive dataset showing average GCSE grades at each school alongside demographic information about the schools. You can download the data yourself here.
For obvious anonymity reasons, the government don’t provide the grades of individual students. Nonetheless, it’s a fascinating dataset that can be used to look at the relationship between different demographic variables and educational achievement, as well as to track changes in GCSE results overtime.</description>
    </item>
    
    <item>
      <title>There Are People Trapped on the Underground</title>
      <link>/posts/trapped-passengers/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/trapped-passengers/</guid>
      <description>…Just kidding (I think!). But this dataset of average daily entries and exits at each Underground station certainly makes it look like there are.
Exhibit 1: A plot showing the average daily entries made across all tube stations between 2007-2017.
Exhibit 2: A plot of both average entries and exits made per day between 2007-2017:
Whoops! Those poor commuters.
TfL do provide an explanation for the discrepancy. In fact, they offer three:</description>
    </item>
    
    <item>
      <title>Cleaning Dirty Excel Sheets in R</title>
      <link>/posts/excel-sheet-cleaning/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/excel-sheet-cleaning/</guid>
      <description>pre.r { color:#000;background-color:#ECECEC;}I spend a great deal of my spare time searching for, and playing with, open source data. Although it’s great fun, a challenge of working with this kind of data is that it usually isn’t stored in a tidy format. Very occasionally, I’ll find a carefully constructed csv made by a generous soul, but most often what I get is a somewhat messy Excel file.</description>
    </item>
    
    <item>
      <title>The Hottest Tube Line: Modelling Tube Temperatures in R</title>
      <link>/posts/tube_temperatures/</link>
      <pubDate>Fri, 31 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>/posts/tube_temperatures/</guid>
      <description>Now, I’m the kind of big tube fanatic who has completed the “Can you name all the stations on the London Underground?” sporcle quiz more times than I can count. But even I have to acknowledge one major drawback of the london tube: it can get really hot down there!
I’ve long suspected the Central line of being the biggest offender in this department, putting it near the bottom in my ranking of favourite tube lines.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>/about/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/about/</guid>
      <description>I am a data scientist based in London working in the EdTech sector, where, amongst other things, I use data to improve instruction and curriculum design.
I am passionate about increasing the use of evidence and statistics to guide social policy. I spend much of my free time working with publically available datasets to explore London demographics, social issues and infrastructure. I mainly code in R and particularly enjoy data visualisation.</description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/contact/</guid>
      <description>On twitter, I&amp;rsquo;m @SophieHeloise - feel free to message, tweet and/or follow me!</description>
    </item>
    
    <item>
      <title>Projects</title>
      <link>/projects/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/projects/</guid>
      <description>Nothing to see here&amp;hellip; Move along!</description>
    </item>
    
  </channel>
</rss>